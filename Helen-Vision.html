<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>HELEN: MEDIA NODES</title>
    <style>
        body { margin:0; overflow:hidden; background:#000; font-family:'Courier New', monospace; }
        #overlay {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            background: rgba(0,0,0,0.8); color: #00ffff;
            display: flex; flex-direction: column; align-items: center; justify-content: center;
            z-index: 100;
        }
        .status { margin-top: 10px; font-size: 14px; color: #aaa; text-align: center; line-height: 1.5; }
        .log-box { 
            margin-top: 20px; padding: 10px; border: 1px solid #555; 
            background: #000; color: #00ff00; font-size: 12px; max-width: 90%; 
            white-space: pre-wrap; text-align: left; height: 100px; overflow-y: scroll;
        }
    </style>
    
    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
                "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/",
                "webxr-polyfill": "https://cdn.jsdelivr.net/npm/webxr-polyfill@latest/build/webxr-polyfill.module.js"
            }
        }
    </script>
</head>
<body>

<video id="camera-feed" autoplay muted playsinline style="display:none;"></video>

<div id="overlay">
    <h1>HELEN: MEDIA DATABASE</h1>
    <div class="status" id="pad-status">
        [ MISSION BRIEFING ]<br>
        1. Find "Encrypted Nodes"<br>
        2. Aim Crosshair<br>
        3. Hold (X) to Decrypt Media
    </div>
    <div class="log-box" id="debug-log">System initialized...</div>
</div>

<script type="module">
    import * as THREE from 'three';
    import { VRButton } from 'three/addons/webxr/VRButton.js';
    import WebXRPolyfill from 'webxr-polyfill';

    const polyfill = new WebXRPolyfill();

    let scene, camera, renderer, dolly;
    let hudTexture, hudContext, hudMesh;
    let camMaterial, videoTrack, currentStream;
    let raycaster = new THREE.Raycaster();
    
    // DATA: What images/videos do you want to show?
    const DATABASE = [
        { type: 'image', src: 'https://upload.wikimedia.org/wikipedia/commons/e/ec/Mona_Lisa%2C_by_Leonardo_da_Vinci%2C_from_C2RMF_retouched.jpg', label: 'ARTIFACT_01' },
        { type: 'video', src: 'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4', label: 'SURVEILLANCE_FOOTAGE' },
        { type: 'image', src: 'https://upload.wikimedia.org/wikipedia/commons/3/3f/HST-SM4.jpeg', label: 'SATELLITE_VIEW' },
        { type: 'video', src: 'https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ElephantsDream.mp4', label: 'DREAM_LOG' }
    ];

    let targets = []; // The wireframe boxes
    let activeHack = { obj: null, progress: 0 }; // Current hacking state
    
    // Hardware IDs
    let torchCamId = null;
    let wideCamId = null;
    let activeCamId = null;

    let visionMode = 0; 
    let lastBtnState = false; 
    let isSwitching = false;

    const SPEED = 0.1; 
    const _moveDir = new THREE.Vector3();
    const _strafeDir = new THREE.Vector3();

    function log(msg) {
        console.log(msg);
        const el = document.getElementById('debug-log');
        el.innerText = msg + "\n" + el.innerText;
    }

    // --- 1. CAMERA LOGIC (Dual Lens) ---
    async function scanCameras() {
        if (!navigator.mediaDevices?.enumerateDevices) return;
        const devices = await navigator.mediaDevices.enumerateDevices();
        const cameras = devices.filter(d => d.kind === 'videoinput');

        for (const cam of cameras) {
            if (cam.label.toLowerCase().includes('front')) continue;
            const label = cam.label.toLowerCase();
            
            if (label.includes('ultra') || label.includes('0.5') || label.includes('wide')) {
                if (!wideCamId) wideCamId = cam.deviceId;
            }
            // Check torch logic (simplified for brevity)
            if (!torchCamId && !wideCamId) {
                 try {
                    const stream = await navigator.mediaDevices.getUserMedia({ video: { deviceId: { exact: cam.deviceId } } });
                    const track = stream.getVideoTracks()[0];
                    if (track.getCapabilities().torch) torchCamId = cam.deviceId;
                    track.stop();
                 } catch(e){}
            }
        }
        startCameraStream(wideCamId || torchCamId);
    }

    async function startCameraStream(preferredId) {
        if(isSwitching) return;
        isSwitching = true;
        if (currentStream) currentStream.getTracks().forEach(t => t.stop());

        try {
            const constraints = preferredId ? { video: { deviceId: { exact: preferredId } } } : { video: { facingMode: 'environment' } };
            const stream = await navigator.mediaDevices.getUserMedia(constraints);
            const video = document.getElementById('camera-feed');
            video.srcObject = stream;
            await new Promise(r => video.onloadedmetadata = r);
            await video.play();

            currentStream = stream;
            videoTrack = stream.getVideoTracks()[0];
            activeCamId = preferredId;
            
            if (camMaterial) {
                camMaterial.uniforms.tDiffuse.value = new THREE.VideoTexture(video);
                camMaterial.uniforms.tDiffuse.value.colorSpace = THREE.SRGBColorSpace;
                camMaterial.uniforms.tDiffuse.value.generateMipmaps = false;
            }
            isSwitching = false;
        } catch (err) { isSwitching = false; }
    }

    // --- 2. HACKING & MEDIA LOGIC ---
    function spawnDecryptedScreen(position, rotation, data) {
        // Create the screen geometry
        const geometry = new THREE.PlaneGeometry(3, 1.8); // 16:9 Aspect Ratio
        let material;

        if (data.type === 'video') {
            const video = document.createElement('video');
            video.src = data.src;
            video.crossOrigin = "anonymous";
            video.loop = true;
            video.muted = true; // Start muted to allow autoplay
            video.play();
            
            const tex = new THREE.VideoTexture(video);
            tex.colorSpace = THREE.SRGBColorSpace;
            material = new THREE.MeshBasicMaterial({ map: tex, side: THREE.DoubleSide });
        } else {
            const tex = new THREE.TextureLoader().load(data.src);
            tex.colorSpace = THREE.SRGBColorSpace;
            material = new THREE.MeshBasicMaterial({ map: tex, side: THREE.DoubleSide });
        }

        const screen = new THREE.Mesh(geometry, material);
        screen.position.copy(position);
        screen.rotation.copy(rotation);
        
        // Add a "frame"
        const frame = new THREE.LineSegments(
            new THREE.EdgesGeometry(geometry),
            new THREE.LineBasicMaterial({ color: 0x00ffff })
        );
        screen.add(frame);

        scene.add(screen);
        
        // Play sound effect (optional/future)
    }

    // --- 3. INIT ENGINE ---
    scanCameras().then(init3D);

    const vertexShader = `varying vec2 vUv; void main() { vUv = uv; gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 ); }`;
    const fragmentShader = `
        uniform sampler2D tDiffuse; uniform float uMode; uniform vec2 uResolution; varying vec2 vUv;
        void main() {
            vec4 color = texture2D(tDiffuse, vUv);
            if (uMode > 0.5) {
                float x = 1.0 / uResolution.x; float y = 1.0 / uResolution.y;
                vec4 horizEdge = -1.0 * texture2D(tDiffuse, vUv + vec2(-x, -y)) + -2.0 * texture2D(tDiffuse, vUv + vec2(-x,  0.0)) + -1.0 * texture2D(tDiffuse, vUv + vec2(-x,  y)) + 1.0 * texture2D(tDiffuse, vUv + vec2( x, -y)) + 2.0 * texture2D(tDiffuse, vUv + vec2( x,  0.0)) + 1.0 * texture2D(tDiffuse, vUv + vec2( x,  y));
                vec4 vertEdge = -1.0 * texture2D(tDiffuse, vUv + vec2(-x, -y)) + -2.0 * texture2D(tDiffuse, vUv + vec2( 0.0, -y)) + -1.0 * texture2D(tDiffuse, vUv + vec2( x, -y)) + 1.0 * texture2D(tDiffuse, vUv + vec2(-x,  y)) + 2.0 * texture2D(tDiffuse, vUv + vec2( 0.0,  y)) + 1.0 * texture2D(tDiffuse, vUv + vec2( x,  y));
                vec3 edge = sqrt((horizEdge.rgb * horizEdge.rgb) + (vertEdge.rgb * vertEdge.rgb));
                float val = length(edge);
                if(val > 0.15) gl_FragColor = vec4(0.0, 1.0, 1.0, 1.0) * val * 2.0; 
                else gl_FragColor = vec4(0.0, 0.05, 0.1, 1.0); 
            } else { gl_FragColor = color; }
        }
    `;

    function init3D() {
        scene = new THREE.Scene();
        dolly = new THREE.Group(); dolly.position.set(0, 0, 5); scene.add(dolly);
        camera = new THREE.PerspectiveCamera(70, window.innerWidth / window.innerHeight, 0.1, 100); dolly.add(camera);

        const video = document.getElementById('camera-feed');
        const vidTex = new THREE.VideoTexture(video); vidTex.colorSpace = THREE.SRGBColorSpace; vidTex.generateMipmaps = false; 
        
        camMaterial = new THREE.ShaderMaterial({
            uniforms: { tDiffuse: { value: vidTex }, uMode: { value: 0.0 }, uResolution: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) } },
            vertexShader: vertexShader, fragmentShader: fragmentShader, depthTest: false, depthWrite: false
        });

        const camPlane = new THREE.Mesh(new THREE.PlaneGeometry(50, 30), camMaterial); camPlane.position.z = -20; camera.add(camPlane); 

        // HUD
        const hudCanvas = document.createElement('canvas'); hudCanvas.width = 1024; hudCanvas.height = 1024;
        hudContext = hudCanvas.getContext('2d'); hudTexture = new THREE.CanvasTexture(hudCanvas); hudTexture.minFilter = THREE.LinearFilter;
        hudMesh = new THREE.Mesh(new THREE.PlaneGeometry(1.5, 1.5), new THREE.MeshBasicMaterial({ map: hudTexture, transparent: true, opacity: 0.9, depthTest: false }));
        hudMesh.position.set(0, 0, -1.5); camera.add(hudMesh);

        scene.add(new THREE.GridHelper(40, 40, 0x00ffff, 0x111111));
        const light = new THREE.DirectionalLight(0xffffff, 2); light.position.set(0, 5, 5); scene.add(light); scene.add(new THREE.AmbientLight(0xffffff, 1));
        createTerminals();

        renderer = new THREE.WebGLRenderer({ antialias: false, alpha: true });
        renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2)); renderer.setSize(window.innerWidth, window.innerHeight); renderer.xr.enabled = true;
        document.body.appendChild(renderer.domElement);
        document.getElementById('overlay').appendChild(VRButton.createButton(renderer));
        
        window.addEventListener("gamepadconnected", (e) => log("Gamepad: " + e.gamepad.id));
        window.addEventListener('resize', () => { camera.aspect = window.innerWidth/window.innerHeight; camera.updateProjectionMatrix(); renderer.setSize(window.innerWidth, window.innerHeight); });
        animate();
    }

    function createTerminals() {
        const geo = new THREE.IcosahedronGeometry(0.5, 0); 
        const mat = new THREE.MeshBasicMaterial({ color: 0x00ffff, wireframe: true });
        
        // Spawn 4 nodes based on our DATABASE
        DATABASE.forEach((data, i) => {
            const mesh = new THREE.Mesh(geo, mat);
            // Spread them out
            const angle = (i / 4) * Math.PI * 2;
            mesh.position.set(Math.sin(angle)*10, 1.5, Math.cos(angle)*10);
            mesh.userData = { isNode: true, data: data, id: i }; // Store info
            scene.add(mesh);
            targets.push(mesh);
        });
    }

    function handleInput() {
        const pads = navigator.getGamepads(); if(!pads[0]) return;
        const pad = pads[0];
        const x = Math.abs(pad.axes[0]) > 0.1 ? pad.axes[0] : 0; const z = Math.abs(pad.axes[1]) > 0.1 ? pad.axes[1] : 0;
        if (x !== 0 || z !== 0) {
            camera.getWorldDirection(_moveDir); _moveDir.y = 0; _moveDir.normalize(); _strafeDir.crossVectors(camera.up, _moveDir).normalize();
            dolly.position.addScaledVector(_moveDir, -z * SPEED); dolly.position.addScaledVector(_strafeDir, x * SPEED);
        }
        
        // TRIANGLE: Lens Switch
        const btnTri = pad.buttons[3].pressed;
        if (btnTri && !lastBtnState) {
            const newMode = visionMode === 0 ? 1 : 0;
            visionMode = newMode;
            if (camMaterial) camMaterial.uniforms.uMode.value = newMode;
            if (newMode === 1 && torchCamId) startCameraStream(torchCamId).then(() => videoTrack?.applyConstraints({advanced:[{torch:true}]}));
            else { videoTrack?.applyConstraints({advanced:[{torch:false}]}); if(wideCamId) setTimeout(()=>startCameraStream(wideCamId),300); }
        }
        lastBtnState = btnTri;

        // X BUTTON (Button 0): Hacking Interaction
        const btnX = pad.buttons[0].pressed;
        
        // Raycast Check
        raycaster.setFromCamera(new THREE.Vector2(0,0), camera);
        const intersects = raycaster.intersectObjects(targets);

        if (intersects.length > 0) {
            const target = intersects[0].object;
            activeHack.obj = target;
            
            if (btnX) {
                activeHack.progress += 2; // Speed of hack
            } else {
                activeHack.progress = Math.max(0, activeHack.progress - 5);
            }

            if (activeHack.progress >= 100) {
                // HACK COMPLETE!
                // 1. Remove Node
                scene.remove(target);
                targets = targets.filter(t => t !== target);
                // 2. Spawn Media Screen
                spawnDecryptedScreen(target.position, target.rotation, target.userData.data);
                activeHack.progress = 0; activeHack.obj = null;
            }
        } else {
            activeHack.obj = null;
            activeHack.progress = 0;
        }
    }

    function updateHUD() {
        if(!hudContext) return;
        const ctx = hudContext; const w = 1024; const h = 1024; ctx.clearRect(0, 0, w, h);
        
        // Mode & Compass
        ctx.textAlign = 'right'; ctx.font = 'bold 30px Courier New';
        if(visionMode === 1) { ctx.fillStyle = '#00ffff'; ctx.fillText("VISION: [CYBER]", w-40, 60); }
        else { ctx.fillStyle = 'rgba(0,255,255,0.5)'; ctx.fillText("VISION: [NORMAL]", w-40, 60); }

        // CROSSHAIR & HACKING UI
        const cx = w/2; const cy = h/2;
        
        if (activeHack.obj) {
            // Target Locked UI
            ctx.strokeStyle = '#ff0000'; ctx.lineWidth = 4;
            ctx.beginPath(); ctx.arc(cx, cy, 40, 0, 2*Math.PI); ctx.stroke();
            
            ctx.fillStyle = '#ff0000'; ctx.textAlign = 'center'; ctx.font = '20px Courier New';
            ctx.fillText("DETECTED: " + activeHack.obj.userData.data.label, cx, cy + 80);
            
            // Progress Bar
            if (activeHack.progress > 0) {
                ctx.fillStyle = '#000'; ctx.fillRect(cx-100, cy+90, 200, 20);
                ctx.fillStyle = '#00ff00'; ctx.fillRect(cx-100, cy+90, activeHack.progress * 2, 20);
                ctx.fillText("DECRYPTING...", cx, cy + 140);
            } else {
                ctx.fillStyle = '#fff'; 
                ctx.fillText("HOLD (X) TO HACK", cx, cy + 140);
            }

        } else {
            // Normal Crosshair
            ctx.strokeStyle = '#00ff00'; ctx.lineWidth = 2; ctx.beginPath();
            ctx.moveTo(cx - 20, cy); ctx.lineTo(cx + 20, cy); ctx.moveTo(cx, cy - 20); ctx.lineTo(cx, cy + 20); ctx.stroke();
        }
        
        hudTexture.needsUpdate = true;
    }

    function animate() {
        renderer.setAnimationLoop(() => { 
            handleInput(); updateHUD(); 
            targets.forEach(t => { t.rotation.x += 0.01; t.rotation.y += 0.01; }); 
            renderer.render(scene, camera); 
        });
    }
</script>
</body>
</html>
