<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>HELEN: DUAL LENS</title>
    <style>
        body { margin:0; overflow:hidden; background:#000; font-family:'Courier New', monospace; }
        #overlay {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            background: rgba(0,0,0,0.8); color: #00ffff;
            display: flex; flex-direction: column; align-items: center; justify-content: center;
            z-index: 100;
        }
        .status { margin-top: 10px; font-size: 14px; color: #aaa; text-align: center; line-height: 1.5; }
        .log-box { 
            margin-top: 20px; padding: 10px; border: 1px solid #555; 
            background: #000; color: #00ff00; font-size: 12px; max-width: 90%; 
            white-space: pre-wrap; text-align: left; height: 150px; overflow-y: scroll;
        }
    </style>
    
    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
                "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/",
                "webxr-polyfill": "https://cdn.jsdelivr.net/npm/webxr-polyfill@latest/build/webxr-polyfill.module.js"
            }
        }
    </script>
</head>
<body>

<video id="camera-feed" autoplay muted playsinline style="display:none;"></video>

<div id="overlay">
    <h1>HELEN: DUAL LENS</h1>
    <div class="status" id="pad-status">
        [ SYSTEM INITIALIZING ]<br>
        Identifying Lenses...
    </div>
    <div class="log-box" id="debug-log">System initialized...</div>
</div>

<script type="module">
    import * as THREE from 'three';
    import { VRButton } from 'three/addons/webxr/VRButton.js';
    import WebXRPolyfill from 'webxr-polyfill';

    const polyfill = new WebXRPolyfill();

    let scene, camera, renderer, dolly;
    let hudTexture, hudContext, hudMesh;
    let camMaterial, videoTrack, currentStream;
    let targets = []; 
    
    // CAMERA ID STORAGE
    let torchCamId = null;
    let wideCamId = null;
    let activeCamId = null;

    let visionMode = 0; // 0 = Normal (Wide), 1 = Cyber (Torch)
    let lastBtnState = false; 
    let isSwitching = false;

    const SPEED = 0.1; 
    const _moveDir = new THREE.Vector3();
    const _strafeDir = new THREE.Vector3();

    function log(msg) {
        console.log(msg);
        const el = document.getElementById('debug-log');
        el.innerText = msg + "\n" + el.innerText;
    }

    // --- 1. HARDWARE SCANNER ---
    async function scanCameras() {
        if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {
            log("Error: MediaDevices API not supported.");
            return;
        }

        log("Scanning Lenses...");
        const devices = await navigator.mediaDevices.enumerateDevices();
        const cameras = devices.filter(d => d.kind === 'videoinput');

        // Step 1: Find Camera with Torch (Usually Main)
        // We brute force check them if the label isn't obvious
        for (const cam of cameras) {
            if (cam.label.toLowerCase().includes('front')) continue;
            
            // Check for Ultra Wide keywords
            const label = cam.label.toLowerCase();
            if (label.includes('ultra') || label.includes('0.5') || label.includes('wide')) {
                log(`Found WIDE: ${label}`);
                if (!wideCamId) wideCamId = cam.deviceId;
            }

            // Check for Torch capability (The only sure way is to open it)
            // Optimization: If we already found one, skip opening others to save time
            if (!torchCamId) {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ video: { deviceId: { exact: cam.deviceId } } });
                    const track = stream.getVideoTracks()[0];
                    const caps = track.getCapabilities();
                    
                    if (caps.torch) {
                        log(`Found TORCH: ${label}`);
                        torchCamId = cam.deviceId;
                    }
                    track.stop(); // Close immediately
                } catch(e) {}
            }
        }

        // Fallbacks
        if (!wideCamId) {
            log("No 'Ultra' label found. Guessing...");
            // If we found a torch cam, maybe another back cam is the wide one?
            const other = cameras.find(c => c.deviceId !== torchCamId && !c.label.toLowerCase().includes('front'));
            if(other) wideCamId = other.deviceId;
        }

        log(`Setup Complete.\nWide ID: ${wideCamId ? 'YES' : 'NO'}\nTorch ID: ${torchCamId ? 'YES' : 'NO'}`);
        
        // Start with Wide if available, else standard
        startCameraStream(wideCamId || torchCamId);
    }

    // --- 2. STREAM SWITCHER ---
    async function startCameraStream(preferredId) {
        if(isSwitching) return;
        isSwitching = true;

        log(`Switching to: ${preferredId === wideCamId ? 'WIDE (0.5x)' : 'MAIN (1x)'}...`);

        // Stop current
        if (currentStream) {
            currentStream.getTracks().forEach(t => t.stop());
        }

        try {
            const constraints = preferredId 
                ? { video: { deviceId: { exact: preferredId } } }
                : { video: { facingMode: 'environment' } }; // Fallback

            const stream = await navigator.mediaDevices.getUserMedia(constraints);
            const video = document.getElementById('camera-feed');
            
            video.srcObject = stream;
            
            // Wait for it to play
            await new Promise(resolve => video.onloadedmetadata = resolve);
            await video.play();

            currentStream = stream;
            videoTrack = stream.getVideoTracks()[0];
            activeCamId = preferredId;
            
            // Update Texture if 3D is running
            if (camMaterial) {
                camMaterial.uniforms.tDiffuse.value = new THREE.VideoTexture(video);
                camMaterial.uniforms.tDiffuse.value.colorSpace = THREE.SRGBColorSpace;
                camMaterial.uniforms.tDiffuse.value.generateMipmaps = false;
            }

            isSwitching = false;
            return true;

        } catch (err) {
            log("Stream Fail: " + err.message);
            isSwitching = false;
            return false;
        }
    }

    async function setVisionMode(mode) {
        visionMode = mode;

        if (mode === 1) { 
            // CYBER MODE -> Needs Torch Camera
            if (activeCamId !== torchCamId && torchCamId) {
                await startCameraStream(torchCamId);
            }
            // Enable Effects
            if (camMaterial) camMaterial.uniforms.uMode.value = 1.0;
            // Turn on Light
            toggleFlashlight(true);

        } else {
            // NORMAL MODE -> Needs Wide Camera
            toggleFlashlight(false); // Off first
            if (camMaterial) camMaterial.uniforms.uMode.value = 0.0;
            
            if (activeCamId !== wideCamId && wideCamId) {
                // Short delay to let light fade before switching lens
                setTimeout(() => startCameraStream(wideCamId), 300);
            }
        }
    }

    async function toggleFlashlight(active) {
        if (!videoTrack) return;
        try {
            await videoTrack.applyConstraints({ advanced: [{ torch: active }] });
        } catch (e) { console.log("No torch on this lens"); }
    }

    // --- START ---
    scanCameras().then(init3D);

    // --- 3D ENGINE (Standard) ---
    const vertexShader = `varying vec2 vUv; void main() { vUv = uv; gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 ); }`;
    const fragmentShader = `
        uniform sampler2D tDiffuse; uniform float uMode; uniform vec2 uResolution; varying vec2 vUv;
        void main() {
            vec4 color = texture2D(tDiffuse, vUv);
            if (uMode > 0.5) {
                float x = 1.0 / uResolution.x; float y = 1.0 / uResolution.y;
                vec4 horizEdge = -1.0 * texture2D(tDiffuse, vUv + vec2(-x, -y)) + -2.0 * texture2D(tDiffuse, vUv + vec2(-x,  0.0)) + -1.0 * texture2D(tDiffuse, vUv + vec2(-x,  y)) + 1.0 * texture2D(tDiffuse, vUv + vec2( x, -y)) + 2.0 * texture2D(tDiffuse, vUv + vec2( x,  0.0)) + 1.0 * texture2D(tDiffuse, vUv + vec2( x,  y));
                vec4 vertEdge = -1.0 * texture2D(tDiffuse, vUv + vec2(-x, -y)) + -2.0 * texture2D(tDiffuse, vUv + vec2( 0.0, -y)) + -1.0 * texture2D(tDiffuse, vUv + vec2( x, -y)) + 1.0 * texture2D(tDiffuse, vUv + vec2(-x,  y)) + 2.0 * texture2D(tDiffuse, vUv + vec2( 0.0,  y)) + 1.0 * texture2D(tDiffuse, vUv + vec2( x,  y));
                vec3 edge = sqrt((horizEdge.rgb * horizEdge.rgb) + (vertEdge.rgb * vertEdge.rgb));
                float val = length(edge);
                if(val > 0.15) gl_FragColor = vec4(0.0, 1.0, 1.0, 1.0) * val * 2.0; 
                else gl_FragColor = vec4(0.0, 0.05, 0.1, 1.0); 
            } else { gl_FragColor = color; }
        }
    `;

    function init3D() {
        scene = new THREE.Scene();
        dolly = new THREE.Group(); dolly.position.set(0, 0, 5); scene.add(dolly);
        camera = new THREE.PerspectiveCamera(70, window.innerWidth / window.innerHeight, 0.1, 100); dolly.add(camera);

        const video = document.getElementById('camera-feed');
        // Initial texture (will be replaced by switcher)
        const vidTex = new THREE.VideoTexture(video); vidTex.colorSpace = THREE.SRGBColorSpace; vidTex.generateMipmaps = false; 
        
        camMaterial = new THREE.ShaderMaterial({
            uniforms: { tDiffuse: { value: vidTex }, uMode: { value: 0.0 }, uResolution: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) } },
            vertexShader: vertexShader, fragmentShader: fragmentShader, depthTest: false, depthWrite: false
        });

        const camPlane = new THREE.Mesh(new THREE.PlaneGeometry(50, 30), camMaterial); camPlane.position.z = -20; camera.add(camPlane); 

        const hudCanvas = document.createElement('canvas'); hudCanvas.width = 1024; hudCanvas.height = 1024;
        hudContext = hudCanvas.getContext('2d'); hudTexture = new THREE.CanvasTexture(hudCanvas); hudTexture.minFilter = THREE.LinearFilter;
        hudMesh = new THREE.Mesh(new THREE.PlaneGeometry(1.5, 1.5), new THREE.MeshBasicMaterial({ map: hudTexture, transparent: true, opacity: 0.9, depthTest: false }));
        hudMesh.position.set(0, 0, -1.5); camera.add(hudMesh);

        scene.add(new THREE.GridHelper(40, 40, 0x00ffff, 0x111111));
        const light = new THREE.DirectionalLight(0xffffff, 2); light.position.set(0, 5, 5); scene.add(light); scene.add(new THREE.AmbientLight(0xffffff, 1));
        createTerminals();

        renderer = new THREE.WebGLRenderer({ antialias: false, alpha: true });
        renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2)); renderer.setSize(window.innerWidth, window.innerHeight); renderer.xr.enabled = true;
        document.body.appendChild(renderer.domElement);
        document.getElementById('overlay').appendChild(VRButton.createButton(renderer));
        
        window.addEventListener("gamepadconnected", (e) => log("Gamepad: " + e.gamepad.id));
        window.addEventListener('resize', () => { camera.aspect = window.innerWidth/window.innerHeight; camera.updateProjectionMatrix(); renderer.setSize(window.innerWidth, window.innerHeight); });
        animate();
    }

    function createTerminals() {
        const geo = new THREE.IcosahedronGeometry(0.5, 0); const mat = new THREE.MeshBasicMaterial({ color: 0x00ffff, wireframe: true });
        for(let i=0; i<8; i++) { const m = new THREE.Mesh(geo, mat); m.position.set((Math.random()-0.5)*20, 1+Math.random()*2, (Math.random()-0.5)*20); scene.add(m); targets.push(m); }
    }

    function handleInput() {
        const pads = navigator.getGamepads(); if(!pads[0]) return;
        const pad = pads[0];
        const x = Math.abs(pad.axes[0]) > 0.1 ? pad.axes[0] : 0; const z = Math.abs(pad.axes[1]) > 0.1 ? pad.axes[1] : 0;
        if (x !== 0 || z !== 0) {
            camera.getWorldDirection(_moveDir); _moveDir.y = 0; _moveDir.normalize(); _strafeDir.crossVectors(camera.up, _moveDir).normalize();
            dolly.position.addScaledVector(_moveDir, -z * SPEED); dolly.position.addScaledVector(_strafeDir, x * SPEED);
        }
        
        // BUTTON 3: TRIANGLE (Toggle)
        const btnState = pad.buttons[3].pressed;
        if (btnState && !lastBtnState) {
            const newMode = visionMode === 0 ? 1 : 0;
            setVisionMode(newMode);
        }
        lastBtnState = btnState;
    }

    function updateHUD() {
        if(!hudContext) return;
        const ctx = hudContext; const w = 1024; const h = 1024; ctx.clearRect(0, 0, w, h);
        ctx.textAlign = 'right'; ctx.font = 'bold 30px Courier New';
        if(visionMode === 1) {
            if (Date.now() % 500 < 250) { ctx.fillStyle = '#00ffff'; ctx.fillText("⚠️ ILLUMINATION ACTIVE", w-40, 100); }
            ctx.fillStyle = '#00ffff'; ctx.fillText("VISION: [CYBER-EDGE]", w-40, 60); ctx.strokeStyle = '#00ffff'; ctx.lineWidth = 4; ctx.strokeRect(w-380, 20, 360, 50);
        } else {
            ctx.fillStyle = 'rgba(0, 255, 255, 0.5)'; ctx.fillText("VISION: [NORMAL 0.5x]", w-40, 60);
        }
        ctx.strokeStyle = visionMode === 1 ? '#00ffff' : 'rgba(0, 255, 0, 0.5)'; ctx.lineWidth = 2; ctx.beginPath();
        ctx.moveTo(w/2 - 20, h/2); ctx.lineTo(w/2 + 20, h/2); ctx.moveTo(w/2, h/2 - 20); ctx.lineTo(w/2, h/2 + 20); ctx.stroke();
        hudTexture.needsUpdate = true;
    }

    function animate() {
        renderer.setAnimationLoop(() => { handleInput(); updateHUD(); targets.forEach(t => t.rotation.y += 0.01); renderer.render(scene, camera); });
    }
</script>
</body>
</html>
